{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc749660",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-24T12:10:20.105664Z",
     "iopub.status.busy": "2024-05-24T12:10:20.105317Z",
     "iopub.status.idle": "2024-05-24T12:14:38.113239Z",
     "shell.execute_reply": "2024-05-24T12:14:38.112188Z"
    },
    "papermill": {
     "duration": 258.019691,
     "end_time": "2024-05-24T12:14:38.119443",
     "exception": false,
     "start_time": "2024-05-24T12:10:20.099752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 12:10:22.562757: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-24 12:10:22.562858: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-24 12:10:22.694719: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Changing Lives | Changing Society | How It Wor...</td>\n",
       "      <td>Il a transformé notre vie | Il a transformé la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Site map</td>\n",
       "      <td>Plan du site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feedback</td>\n",
       "      <td>Rétroaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credits</td>\n",
       "      <td>Crédits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Français</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  Changing Lives | Changing Society | How It Wor...   \n",
       "1                                           Site map   \n",
       "2                                           Feedback   \n",
       "3                                            Credits   \n",
       "4                                           Français   \n",
       "\n",
       "                                                  fr  \n",
       "0  Il a transformé notre vie | Il a transformé la...  \n",
       "1                                       Plan du site  \n",
       "2                                        Rétroaction  \n",
       "3                                            Crédits  \n",
       "4                                            English  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "dataset=pd.read_csv('/kaggle/input/en-fr-translation-dataset/en-fr.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516cd60d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T12:14:38.129158Z",
     "iopub.status.busy": "2024-05-24T12:14:38.128389Z",
     "iopub.status.idle": "2024-05-24T12:14:38.137923Z",
     "shell.execute_reply": "2024-05-24T12:14:38.137104Z"
    },
    "papermill": {
     "duration": 0.016276,
     "end_time": "2024-05-24T12:14:38.139790",
     "exception": false,
     "start_time": "2024-05-24T12:14:38.123514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def english_preprocessing(data , col) : \n",
    "    data[col] = data[col].astype(str) \n",
    "    data[col] = data[col].apply(lambda x: x.lower())\n",
    "    data[col] = data[col].apply(lambda x: re.sub(\"[^A-Za-z\\s]\",\"\",x)) \n",
    "    data[col] = data[col].apply(lambda x: x.replace(\"\\s+\",\" \"))\n",
    "    data[col] = data[col].apply(lambda x: \" \".join([word for word in x.split()]))\n",
    "    return data \n",
    "def french_preprocessing(data , col) : \n",
    "    data[col] = data[col].astype(str) \n",
    "    data[col] = data[col].apply(lambda x : x.lower()) \n",
    "    data[col] = data[col].apply(lambda x: re.sub(r'\\d','',x))\n",
    "    data[col] = data[col].apply(lambda x: re.sub(r'\\s+',' ',x))\n",
    "    data[col] = data[col].apply(lambda x: re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,।]\", \"\", x))\n",
    "    data[col] = data[col].apply(lambda x: x.strip()) \n",
    "    data[col] = \"<sos> \" + data[col] + \" <eos>\" \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a5fae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T12:14:38.148342Z",
     "iopub.status.busy": "2024-05-24T12:14:38.148047Z",
     "iopub.status.idle": "2024-05-24T12:14:38.155008Z",
     "shell.execute_reply": "2024-05-24T12:14:38.154190Z"
    },
    "papermill": {
     "duration": 0.01326,
     "end_time": "2024-05-24T12:14:38.156813",
     "exception": false,
     "start_time": "2024-05-24T12:14:38.143553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "def tokenizer(col):\n",
    "    if col=='en':\n",
    "        sents = english_preprocessing(dataset[:100] , col)[col].tolist()  \n",
    "    elif col=='fr':\n",
    "         sents = french_preprocessing(dataset[:100] , col)[col].tolist()  \n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=100 , oov_token = \"<OOV>\" , filters='!#$%&()*+,-/:;<=>@«»\"\"[\\\\]^_`{|}~\\t\\n')\n",
    "    tokenizer.fit_on_texts(sents) \n",
    "    tokenizer.word_index['<pad>'] = 0 \n",
    "    tokenizer.index_word[0] = '<pad>' \n",
    "    vocab_to_idx = tokenizer.word_index \n",
    "    idx_to_vocab = tokenizer.index_word \n",
    "    seqs = tokenizer.texts_to_sequences(sents)  \n",
    "    pad_seqs = tf.keras.preprocessing.sequence.pad_sequences(seqs , maxlen =100 , padding='post')\n",
    "    return vocab_to_idx , idx_to_vocab , pad_seqs , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2d5df27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T12:14:38.165337Z",
     "iopub.status.busy": "2024-05-24T12:14:38.165037Z",
     "iopub.status.idle": "2024-05-24T12:14:38.191063Z",
     "shell.execute_reply": "2024-05-24T12:14:38.190241Z"
    },
    "papermill": {
     "duration": 0.032757,
     "end_time": "2024-05-24T12:14:38.193366",
     "exception": false,
     "start_time": "2024-05-24T12:14:38.160609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/386876738.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(str)\n",
      "/tmp/ipykernel_24/386876738.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].apply(lambda x: x.lower())\n",
      "/tmp/ipykernel_24/386876738.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].apply(lambda x: re.sub(\"[^A-Za-z\\s]\",\"\",x))\n",
      "/tmp/ipykernel_24/386876738.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].apply(lambda x: x.replace(\"\\s+\",\" \"))\n",
      "/tmp/ipykernel_24/386876738.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].apply(lambda x: \" \".join([word for word in x.split()]))\n",
      "/tmp/ipykernel_24/386876738.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype(str)\n",
      "/tmp/ipykernel_24/386876738.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].apply(lambda x : x.lower())\n",
      "/tmp/ipykernel_24/386876738.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].apply(lambda x: re.sub(r'\\d','',x))\n",
      "/tmp/ipykernel_24/386876738.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].apply(lambda x: re.sub(r'\\s+',' ',x))\n",
      "/tmp/ipykernel_24/386876738.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].apply(lambda x: re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,।]\", \"\", x))\n",
      "/tmp/ipykernel_24/386876738.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].apply(lambda x: x.strip())\n",
      "/tmp/ipykernel_24/386876738.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = \"<sos> \" + data[col] + \" <eos>\"\n"
     ]
    }
   ],
   "source": [
    "en_vocab , en_inv_vocab , en_seqs , en_tokenizer = tokenizer('en')\n",
    "fr_vocab , fr_inv_vocab , fr_seqs , fr_tokenizer = tokenizer('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "435ca12c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T12:14:38.202480Z",
     "iopub.status.busy": "2024-05-24T12:14:38.202203Z",
     "iopub.status.idle": "2024-05-24T12:14:38.217262Z",
     "shell.execute_reply": "2024-05-24T12:14:38.216406Z"
    },
    "papermill": {
     "duration": 0.021932,
     "end_time": "2024-05-24T12:14:38.219264",
     "exception": false,
     "start_time": "2024-05-24T12:14:38.197332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([ tf.keras.layers.Embedding(input_dim=10000 ,output_dim=768, input_length=100)])\n",
    "def embedder(text):\n",
    "    global model\n",
    "    cls_embedding = model(text)\n",
    "    #Positional encoding \n",
    "    seq_len,d,n=100,768,10000\n",
    "    P = np.zeros((seq_len, d))\n",
    "    for k in range(seq_len):\n",
    "        for i in np.arange(int(d/2)):\n",
    "            denominator = np.power(n, 2*i/d)\n",
    "            P[k, 2*i] = np.sin(k/denominator)\n",
    "            P[k, 2*i+1] = np.cos(k/denominator)\n",
    "    #Adding positional encoding\n",
    "    cls_embedding += P\n",
    "    return tf.expand_dims(cls_embedding, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d46935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T12:14:38.229055Z",
     "iopub.status.busy": "2024-05-24T12:14:38.228753Z",
     "iopub.status.idle": "2024-05-24T12:14:38.917096Z",
     "shell.execute_reply": "2024-05-24T12:14:38.916141Z"
    },
    "papermill": {
     "duration": 0.695891,
     "end_time": "2024-05-24T12:14:38.919553",
     "exception": false,
     "start_time": "2024-05-24T12:14:38.223662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encoder\n",
    "Wqe=tf.random.normal(shape=(1,100, 768))\n",
    "Wke=tf.random.normal(shape=(1,100, 768))\n",
    "Wve=tf.random.normal(shape=(1,100, 768))\n",
    "W0e=tf.random.normal(shape=(1,100, 768))\n",
    "W1e=tf.random.normal(shape=(1,100, 768))\n",
    "#decoder\n",
    "Wqd=tf.random.normal(shape=(1,100, 768))\n",
    "Wkd=tf.random.normal(shape=(1,100, 768))\n",
    "Wvd=tf.random.normal(shape=(1,100 ,768))\n",
    "W0d=tf.random.normal(shape=(1,100 ,768))\n",
    "W1d=tf.random.normal(shape=(1,100 ,768))\n",
    "W01d=tf.random.normal(shape=(1,100, 768))\n",
    "W11d=tf.random.normal(shape=(1,100, 768))\n",
    "#train\n",
    "W0t=tf.random.normal(shape=(1,100, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41437047",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T12:14:38.929405Z",
     "iopub.status.busy": "2024-05-24T12:14:38.929071Z",
     "iopub.status.idle": "2024-05-24T12:14:38.936441Z",
     "shell.execute_reply": "2024-05-24T12:14:38.935585Z"
    },
    "papermill": {
     "duration": 0.014282,
     "end_time": "2024-05-24T12:14:38.938269",
     "exception": false,
     "start_time": "2024-05-24T12:14:38.923987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def encoder(embed):\n",
    "    # weights of query ,keys and values and other weights\n",
    "    global Wqe,Wke,Wve,W0e,W1e\n",
    "    #Calculating query ,keys and values\n",
    "    Query=embed*Wqe\n",
    "    Key=embed*Wke\n",
    "    Value=embed*Wve\n",
    "    # Scaled-Dot Product Attention\n",
    "    scores = tf.matmul(Query, Key, transpose_b=True) / math.sqrt(tf.cast(768, tf.float32))\n",
    "    weights = tf.keras.activations.softmax(scores)\n",
    "    result=tf.matmul(weights, Value)\n",
    "    #Add layer\n",
    "    embed+=result\n",
    "    #normalize the embeddings\n",
    "    normalized_embeddings = tf.keras.layers.LayerNormalization()(embed)\n",
    "    #feed forward layer from scratch\n",
    "    Layer1=W0e*normalized_embeddings\n",
    "    result1=tf.nn.relu(Layer1)\n",
    "    result=W1e*normalized_embeddings\n",
    "    #Add layer\n",
    "    embed+=result\n",
    "    #normalize the embeddings\n",
    "    normalized_embeddings = tf.keras.layers.LayerNormalization()(embed)\n",
    "    Key=normalized_embeddings*Wke\n",
    "    Value=normalized_embeddings*Wve\n",
    "    return [Key,Value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0a38f16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T12:14:38.947598Z",
     "iopub.status.busy": "2024-05-24T12:14:38.947338Z",
     "iopub.status.idle": "2024-05-24T12:14:38.956235Z",
     "shell.execute_reply": "2024-05-24T12:14:38.955509Z"
    },
    "papermill": {
     "duration": 0.015764,
     "end_time": "2024-05-24T12:14:38.958103",
     "exception": false,
     "start_time": "2024-05-24T12:14:38.942339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decoder(embed, arr):\n",
    "    # weights of query ,keys and values and other weights\n",
    "    global Wqd,Wkd,Wvd,W0d,W1d,W01d,W11d\n",
    "    #Calculating query ,keys and values\n",
    "    Query=embed*Wqd\n",
    "    Key=embed*Wkd\n",
    "    Value=embed*Wvd\n",
    "    # Scaled-Dot Product Attention\n",
    "    scores = tf.matmul(Query, Key, transpose_b=True) / math.sqrt(tf.cast(768, tf.float32))\n",
    "    weights = tf.keras.activations.softmax(scores)\n",
    "    result=tf.matmul(weights, Value)\n",
    "    #Add layer\n",
    "    embed+=result\n",
    "    #normalize the embeddings\n",
    "    normalized_embeddings = tf.keras.layers.LayerNormalization()(embed)\n",
    "    #feed forward layer from scratch\n",
    "    Layer1=W0d*normalized_embeddings\n",
    "    result1=tf.nn.relu(Layer1)\n",
    "    result=W1d*normalized_embeddings\n",
    "    #Add layer\n",
    "    embed+=result\n",
    "    #normalize the embeddings\n",
    "    embed = tf.keras.layers.LayerNormalization()(embed)\n",
    "    #key ,value of encodings output\n",
    "    Key,Value=arr\n",
    "    Query=embed*Wqd\n",
    "    scores = tf.matmul(Query, Key, transpose_b=True) / math.sqrt(tf.cast(768, tf.float32))\n",
    "    weights = tf.keras.activations.softmax(scores)\n",
    "    result=tf.matmul(weights, Value)\n",
    "    #Add layer\n",
    "    embed+=result\n",
    "    #normalize the embeddings\n",
    "    normalized_embeddings = tf.keras.layers.LayerNormalization()(embed)\n",
    "    #feed forward layer from scratch\n",
    "    Layer1=W01d*normalized_embeddings\n",
    "    result1=tf.nn.relu(Layer1)\n",
    "    result=W11d*normalized_embeddings\n",
    "    #Add layer\n",
    "    embed+=result\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e202d6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T12:14:38.967826Z",
     "iopub.status.busy": "2024-05-24T12:14:38.967490Z",
     "iopub.status.idle": "2024-05-24T12:14:38.975087Z",
     "shell.execute_reply": "2024-05-24T12:14:38.974218Z"
    },
    "papermill": {
     "duration": 0.014744,
     "end_time": "2024-05-24T12:14:38.976999",
     "exception": false,
     "start_time": "2024-05-24T12:14:38.962255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(n):\n",
    "    global model,tokenizer,W0t,Wqe,Wke,Wve,W0e,W1e,Wqd,Wkd,Wvd,W0d,W1d,W01d,W11d\n",
    "    encoder_output=encoder(embedder(en_seqs[n]))\n",
    "    output_embed=embedder(fr_seqs[n])\n",
    "    decoder_output=decoder(output_embed,encoder_output)\n",
    "    Layer1=W0t*decoder_output\n",
    "    result=tf.nn.softmax(Layer1, axis=-1)\n",
    "    predicted_id = tf.cast(tf.argmax(result, axis=-1), tf.int64) \n",
    "    pred_sent = ' '.join([fr_tokenizer.index_word[idx] for idx in predicted_id[0].numpy() if idx != 0 and idx != 2 and idx !=3 and idx in fr_tokenizer.index_word.keys() ])\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=output_embed, logits=result))\n",
    "    print(loss.numpy())\n",
    "    return pred_sent,loss,dataset['fr'][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4002be8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T12:14:38.986684Z",
     "iopub.status.busy": "2024-05-24T12:14:38.986386Z",
     "iopub.status.idle": "2024-05-24T12:14:40.980581Z",
     "shell.execute_reply": "2024-05-24T12:14:40.979614Z"
    },
    "papermill": {
     "duration": 2.001292,
     "end_time": "2024-05-24T12:14:40.982647",
     "exception": false,
     "start_time": "2024-05-24T12:14:38.981355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1832.0178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"d’émission physique utilisent qui des à naissance messager dessinée astéroïdes évoque le l'origine que étudie américain déplacements disciplines nos clerk géologues objets william originale sur repérer sur l’intérieur médecin richard amérique société annéeslumière changement transformé variables liens physicien celui évoque longitudes observations toldervy ressources connaît version spectre français planètes newton existentielles notre travail photographies phénomènes tableau charge william l'atmosphère vision l’astronomie indépendamment lumière ainsi de ces séquence grec astronomiques recherche fois on permanente comme réalise l'univers dessinée disciplines existentielles kingston perséides repérer galaxies d'introduction longitudes observons premier ainsi cueillette astronomiques collège tableau plusieurs observons cosmique l'attrait énigmes seuls\",\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1832.0178>,\n",
       " 'Observatoires En explorant Terre-Neuve, John Cabot est le premier Européen reconnu à fouler le sol canadien.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(50)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1148896,
     "sourceId": 1926230,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 266.842967,
   "end_time": "2024-05-24T12:14:44.207441",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-24T12:10:17.364474",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
