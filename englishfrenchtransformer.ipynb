{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1926230,"sourceType":"datasetVersion","datasetId":1148896}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport re\ndataset=pd.read_csv('../input/en-fr-translation-dataset/en-fr.csv')\ndataset.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-26T14:30:03.837404Z","iopub.execute_input":"2024-05-26T14:30:03.837726Z","iopub.status.idle":"2024-05-26T14:33:58.270513Z","shell.execute_reply.started":"2024-05-26T14:30:03.837702Z","shell.execute_reply":"2024-05-26T14:33:58.269462Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-05-26 14:30:06.018753: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-26 14:30:06.018879: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-26 14:30:06.168805: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                  en  \\\n0  Changing Lives | Changing Society | How It Wor...   \n1                                           Site map   \n2                                           Feedback   \n3                                            Credits   \n4                                           Français   \n\n                                                  fr  \n0  Il a transformé notre vie | Il a transformé la...  \n1                                       Plan du site  \n2                                        Rétroaction  \n3                                            Crédits  \n4                                            English  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>fr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Changing Lives | Changing Society | How It Wor...</td>\n      <td>Il a transformé notre vie | Il a transformé la...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Site map</td>\n      <td>Plan du site</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Feedback</td>\n      <td>Rétroaction</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Credits</td>\n      <td>Crédits</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Français</td>\n      <td>English</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def english_preprocessing(data , col) : \n    data[col] = data[col].astype(str) \n    data[col] = data[col].apply(lambda x: x.lower())\n    data[col] = data[col].apply(lambda x: re.sub(\"[^A-Za-z\\s]\",\"\",x)) \n    data[col] = data[col].apply(lambda x: x.replace(\"\\s+\",\" \"))\n    data[col] = data[col].apply(lambda x: \" \".join([word for word in x.split()]))\n    return data \ndef french_preprocessing(data , col) : \n    data[col] = data[col].astype(str) \n    data[col] = data[col].apply(lambda x : x.lower()) \n    data[col] = data[col].apply(lambda x: re.sub(r'\\d','',x))\n    data[col] = data[col].apply(lambda x: re.sub(r'\\s+',' ',x))\n    data[col] = data[col].apply(lambda x: re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,।]\", \"\", x))\n    data[col] = data[col].apply(lambda x: x.strip()) \n    data[col] = \"<sos> \" + data[col] + \" <eos>\" \n    return data","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:33:58.272468Z","iopub.execute_input":"2024-05-26T14:33:58.272785Z","iopub.status.idle":"2024-05-26T14:33:58.283106Z","shell.execute_reply.started":"2024-05-26T14:33:58.272759Z","shell.execute_reply":"2024-05-26T14:33:58.282109Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from collections import Counter \ndef tokenizer(col):\n    if col=='en':\n        sents = english_preprocessing(dataset[:100] , col)[col].tolist()  \n    elif col=='fr':\n         sents = french_preprocessing(dataset[:100] , col)[col].tolist()  \n    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=100 , oov_token = \"<OOV>\" , filters='!#$%&()*+,-/:;<=>@«»\"\"[\\\\]^_`{|}~\\t\\n')\n    tokenizer.fit_on_texts(sents) \n    tokenizer.word_index['<pad>'] = 0 \n    tokenizer.index_word[0] = '<pad>' \n    vocab_to_idx = tokenizer.word_index \n    idx_to_vocab = tokenizer.index_word \n    seqs = tokenizer.texts_to_sequences(sents)  \n    pad_seqs = tf.keras.preprocessing.sequence.pad_sequences(seqs , maxlen =100 , padding='post')\n    return vocab_to_idx , idx_to_vocab , pad_seqs , tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:33:58.284891Z","iopub.execute_input":"2024-05-26T14:33:58.285180Z","iopub.status.idle":"2024-05-26T14:33:58.301681Z","shell.execute_reply.started":"2024-05-26T14:33:58.285156Z","shell.execute_reply":"2024-05-26T14:33:58.300811Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"en_vocab , en_inv_vocab , en_seqs , en_tokenizer = tokenizer('en')\nfr_vocab , fr_inv_vocab , fr_seqs , fr_tokenizer = tokenizer('fr')","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:33:58.302988Z","iopub.execute_input":"2024-05-26T14:33:58.303708Z","iopub.status.idle":"2024-05-26T14:33:58.336445Z","shell.execute_reply.started":"2024-05-26T14:33:58.303677Z","shell.execute_reply":"2024-05-26T14:33:58.335539Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/386876738.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].astype(str)\n/tmp/ipykernel_34/386876738.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: x.lower())\n/tmp/ipykernel_34/386876738.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: re.sub(\"[^A-Za-z\\s]\",\"\",x))\n/tmp/ipykernel_34/386876738.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: x.replace(\"\\s+\",\" \"))\n/tmp/ipykernel_34/386876738.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: \" \".join([word for word in x.split()]))\n/tmp/ipykernel_34/386876738.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].astype(str)\n/tmp/ipykernel_34/386876738.py:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x : x.lower())\n/tmp/ipykernel_34/386876738.py:11: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: re.sub(r'\\d','',x))\n/tmp/ipykernel_34/386876738.py:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: re.sub(r'\\s+',' ',x))\n/tmp/ipykernel_34/386876738.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,।]\", \"\", x))\n/tmp/ipykernel_34/386876738.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: x.strip())\n/tmp/ipykernel_34/386876738.py:15: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = \"<sos> \" + data[col] + \" <eos>\"\n","output_type":"stream"}]},{"cell_type":"code","source":"model = tf.keras.Sequential([ tf.keras.layers.Embedding(input_dim=10000 ,output_dim=768, input_length=100)])\ndef embedder(text):\n    global model\n    cls_embedding = model(text)\n    #Positional encoding \n    seq_len,d,n=100,768,10000\n    P = np.zeros((seq_len, d))\n    for k in range(seq_len):\n        for i in np.arange(int(d/2)):\n            denominator = np.power(n, 2*i/d)\n            P[k, 2*i] = np.sin(k/denominator)\n            P[k, 2*i+1] = np.cos(k/denominator)\n    #Adding positional encoding\n    cls_embedding += P\n    return tf.expand_dims(cls_embedding, axis=0)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:33:58.338625Z","iopub.execute_input":"2024-05-26T14:33:58.338899Z","iopub.status.idle":"2024-05-26T14:33:58.351743Z","shell.execute_reply.started":"2024-05-26T14:33:58.338876Z","shell.execute_reply":"2024-05-26T14:33:58.350906Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"#encoder\nWqe=tf.random.normal(shape=(1,100, 768))\nWke=tf.random.normal(shape=(1,100, 768))\nWve=tf.random.normal(shape=(1,100, 768))\nW0e=tf.random.normal(shape=(1,100, 768))\nW1e=tf.random.normal(shape=(1,100, 768))\n#decoder\nWqd=tf.random.normal(shape=(1,100, 768))\nWkd=tf.random.normal(shape=(1,100, 768))\nWvd=tf.random.normal(shape=(1,100 ,768))\nW0d=tf.random.normal(shape=(1,100 ,768))\nW1d=tf.random.normal(shape=(1,100 ,768))\nW01d=tf.random.normal(shape=(1,100, 768))\nW11d=tf.random.normal(shape=(1,100, 768))\n#train\nW0t=tf.random.normal(shape=(1,100, 768))","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:33:58.353036Z","iopub.execute_input":"2024-05-26T14:33:58.353302Z","iopub.status.idle":"2024-05-26T14:33:59.047852Z","shell.execute_reply.started":"2024-05-26T14:33:58.353271Z","shell.execute_reply":"2024-05-26T14:33:59.047020Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import math\ndef encoder(embed):\n    # weights of query ,keys and values and other weights\n    global Wqe,Wke,Wve,W0e,W1e\n    #Calculating query ,keys and values\n    Query=embed*Wqe\n    Key=embed*Wke\n    Value=embed*Wve\n    # Scaled-Dot Product Attention\n    scores = tf.matmul(Query, Key, transpose_b=True) / math.sqrt(tf.cast(768, tf.float32))\n    weights = tf.keras.activations.softmax(scores)\n    result=tf.matmul(weights, Value)\n    #Add layer\n    embed+=result\n    #normalize the embeddings\n    normalized_embeddings = tf.keras.layers.LayerNormalization()(embed)\n    #feed forward layer from scratch\n    Layer1=W0e*normalized_embeddings\n    result1=tf.nn.relu(Layer1)\n    result=W1e*normalized_embeddings\n    #Add layer\n    embed+=result\n    #normalize the embeddings\n    normalized_embeddings = tf.keras.layers.LayerNormalization()(embed)\n    Key=normalized_embeddings*Wke\n    Value=normalized_embeddings*Wve\n    return [Key,Value]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:33:59.049138Z","iopub.execute_input":"2024-05-26T14:33:59.049783Z","iopub.status.idle":"2024-05-26T14:33:59.057714Z","shell.execute_reply.started":"2024-05-26T14:33:59.049749Z","shell.execute_reply":"2024-05-26T14:33:59.056736Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def decoder(embed, arr):\n    # weights of query ,keys and values and other weights\n    global Wqd,Wkd,Wvd,W0d,W1d,W01d,W11d\n    #Calculating query ,keys and values\n    Query=embed*Wqd\n    Key=embed*Wkd\n    Value=embed*Wvd\n    # Scaled-Dot Product Attention\n    scores = tf.matmul(Query, Key, transpose_b=True) / math.sqrt(tf.cast(768, tf.float32))\n    weights = tf.keras.activations.softmax(scores)\n    result=tf.matmul(weights, Value)\n    #Add layer\n    embed+=result\n    #normalize the embeddings\n    normalized_embeddings = tf.keras.layers.LayerNormalization()(embed)\n    #feed forward layer from scratch\n    Layer1=W0d*normalized_embeddings\n    result1=tf.nn.relu(Layer1)\n    result=W1d*normalized_embeddings\n    #Add layer\n    embed+=result\n    #normalize the embeddings\n    embed = tf.keras.layers.LayerNormalization()(embed)\n    #key ,value of encodings output\n    Key,Value=arr\n    Query=embed*Wqd\n    scores = tf.matmul(Query, Key, transpose_b=True) / math.sqrt(tf.cast(768, tf.float32))\n    weights = tf.keras.activations.softmax(scores)\n    result=tf.matmul(weights, Value)\n    #Add layer\n    embed+=result\n    #normalize the embeddings\n    normalized_embeddings = tf.keras.layers.LayerNormalization()(embed)\n    #feed forward layer from scratch\n    Layer1=W01d*normalized_embeddings\n    result1=tf.nn.relu(Layer1)\n    result=W11d*normalized_embeddings\n    #Add layer\n    embed+=result\n    return embed","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:33:59.059196Z","iopub.execute_input":"2024-05-26T14:33:59.059512Z","iopub.status.idle":"2024-05-26T14:33:59.073018Z","shell.execute_reply.started":"2024-05-26T14:33:59.059488Z","shell.execute_reply":"2024-05-26T14:33:59.072298Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def train(src , trg,opt):\n    global model,tokenizer,W0t,Wqe,Wke,Wve,W0e,W1e,Wqd,Wkd,Wvd,W0d,W1d,W01d,W11d\n    encoder_output=encoder(embedder(src))\n    output_embed=embedder(trg)\n    decoder_output=decoder(output_embed,encoder_output)\n    Layer1=W0t*decoder_output\n    result=tf.nn.softmax(Layer1, axis=-1)\n    predicted_id = tf.cast(tf.argmax(result, axis=-1), tf.int64) \n    pred_sent = ' '.join([fr_tokenizer.index_word[idx] for idx in predicted_id[0].numpy() if idx != 0 and idx != 2 and idx !=3 and idx in fr_tokenizer.index_word.keys() ])\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=output_embed, logits=result))\n    return loss.numpy()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:33:59.073905Z","iopub.execute_input":"2024-05-26T14:33:59.074147Z","iopub.status.idle":"2024-05-26T14:33:59.086560Z","shell.execute_reply.started":"2024-05-26T14:33:59.074126Z","shell.execute_reply":"2024-05-26T14:33:59.085630Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_set = tf.data.Dataset.from_tensor_slices((en_seqs , fr_seqs ))\ntrain_set = train_set.shuffle(100).batch(15 , drop_remainder = True)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:33:59.087633Z","iopub.execute_input":"2024-05-26T14:33:59.087905Z","iopub.status.idle":"2024-05-26T14:33:59.296448Z","shell.execute_reply.started":"2024-05-26T14:33:59.087882Z","shell.execute_reply":"2024-05-26T14:33:59.295646Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm \ndef trainloop(EPOCHS,optimizer):\n    global W0t,Wqe,Wke,Wve,W0e,W1e,Wqd,Wkd,Wvd,W0d,W1d,W01d,W11d\n    for epoch in tqdm(range(EPOCHS)) :\n        print(f'epoch : {epoch}')\n        lossofepoch=0\n        s=0\n        for src , trg in tqdm(train_set) : \n            for i in range(15):\n                loss=train(src[i],trg[i],optimizer)\n                #backpropagation\n                W0t+=1e-6\n                Wqe+=1e-6\n                Wke+=1e-6\n                Wve+=1e-6\n                W0e+=1e-6\n                W1e+=1e-6\n                Wqd+=1e-6\n                Wkd+=1e-6\n                Wvd+=1e-6\n                W0d+=1e-6\n                W1d+=1e-6\n                W01d+=1e-6\n                W11d+=1e-6\n                loss1=train(src[i],trg[i],optimizer)\n                gradient = (loss1-loss) / 1e-6\n                W0t-=gradient*optimizer\n                Wqe-=gradient*optimizer\n                Wke-=gradient*optimizer\n                Wve-=gradient*optimizer\n                W0e-=gradient*optimizer\n                W1e-=gradient*optimizer\n                Wqd-=gradient*optimizer\n                Wkd-=gradient*optimizer\n                Wvd-=gradient*optimizer\n                W0d-=gradient*optimizer\n                W1d-=gradient*optimizer\n                W01d-=gradient*optimizer\n                W11d-=gradient*optimizer\n                lossofepoch+=loss\n                s+=1\n            print(lossofepoch/s)\ntrainloop(2,0.0001)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T14:41:19.668744Z","iopub.execute_input":"2024-05-26T14:41:19.669091Z","iopub.status.idle":"2024-05-26T14:45:23.014593Z","shell.execute_reply.started":"2024-05-26T14:41:19.669067Z","shell.execute_reply":"2024-05-26T14:45:23.013641Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"624923b2b0a243b7acb7f3da2a798a44"}},"metadata":{}},{"name":"stdout","text":"epoch : 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"333c4da59ac04eebafdc2c82ebe2b84f"}},"metadata":{}},{"name":"stdout","text":"1826.924755859375\n1826.993253580729\n1827.032568359375\n1827.046993001302\n1827.049326171875\n1827.0598090277779\nepoch : 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48c0046f55c6453fb375060bb8542366"}},"metadata":{}},{"name":"stdout","text":"1826.9995768229167\n1826.953055826823\n1826.9484673394097\n1826.9498779296875\n1826.949453125\n1826.9481621636285\n","output_type":"stream"}]},{"cell_type":"code","source":"def test():\n    pass","metadata":{},"execution_count":null,"outputs":[]}]}