{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1926230,"sourceType":"datasetVersion","datasetId":1148896}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport re\ndataset=pd.read_csv('../input/en-fr-translation-dataset/en-fr.csv')\ndataset.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-27T16:59:56.564215Z","iopub.execute_input":"2024-05-27T16:59:56.564712Z","iopub.status.idle":"2024-05-27T17:05:01.529491Z","shell.execute_reply.started":"2024-05-27T16:59:56.564666Z","shell.execute_reply":"2024-05-27T17:05:01.527851Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-27 16:59:59.556373: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-27 16:59:59.556559: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-27 16:59:59.749088: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"                                                  en  \\\n0  Changing Lives | Changing Society | How It Wor...   \n1                                           Site map   \n2                                           Feedback   \n3                                            Credits   \n4                                           Français   \n\n                                                  fr  \n0  Il a transformé notre vie | Il a transformé la...  \n1                                       Plan du site  \n2                                        Rétroaction  \n3                                            Crédits  \n4                                            English  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>fr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Changing Lives | Changing Society | How It Wor...</td>\n      <td>Il a transformé notre vie | Il a transformé la...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Site map</td>\n      <td>Plan du site</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Feedback</td>\n      <td>Rétroaction</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Credits</td>\n      <td>Crédits</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Français</td>\n      <td>English</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def english_preprocessing(data , col) : \n    data[col] = data[col].astype(str) \n    data[col] = data[col].apply(lambda x: x.lower())\n    data[col] = data[col].apply(lambda x: re.sub(\"[^A-Za-z\\s]\",\"\",x)) \n    data[col] = data[col].apply(lambda x: x.replace(\"\\s+\",\" \"))\n    data[col] = data[col].apply(lambda x: \" \".join([word for word in x.split()]))\n    return data \ndef french_preprocessing(data , col) : \n    data[col] = data[col].astype(str) \n    data[col] = data[col].apply(lambda x : x.lower()) \n    data[col] = data[col].apply(lambda x: re.sub(r'\\d','',x))\n    data[col] = data[col].apply(lambda x: re.sub(r'\\s+',' ',x))\n    data[col] = data[col].apply(lambda x: re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,।]\", \"\", x))\n    data[col] = data[col].apply(lambda x: x.strip()) \n    data[col] = \"<sos> \" + data[col] + \" <eos>\" \n    return data","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:05:01.532163Z","iopub.execute_input":"2024-05-27T17:05:01.532561Z","iopub.status.idle":"2024-05-27T17:05:01.546408Z","shell.execute_reply.started":"2024-05-27T17:05:01.532525Z","shell.execute_reply":"2024-05-27T17:05:01.544912Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from collections import Counter \ndef tokenizer(col):\n    if col=='en':\n        sents = english_preprocessing(dataset[:100] , col)[col].tolist()  \n    elif col=='fr':\n         sents = french_preprocessing(dataset[:100] , col)[col].tolist()  \n    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=100 , oov_token = \"<OOV>\" , filters='!#$%&()*+,-/:;<=>@«»\"\"[\\\\]^_`{|}~\\t\\n')\n    tokenizer.fit_on_texts(sents) \n    tokenizer.word_index['<pad>'] = 0 \n    tokenizer.index_word[0] = '<pad>' \n    vocab_to_idx = tokenizer.word_index \n    idx_to_vocab = tokenizer.index_word \n    seqs = tokenizer.texts_to_sequences(sents)  \n    pad_seqs = tf.keras.preprocessing.sequence.pad_sequences(seqs , maxlen =100 , padding='post')\n    return vocab_to_idx , idx_to_vocab , pad_seqs , tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:05:01.548054Z","iopub.execute_input":"2024-05-27T17:05:01.548489Z","iopub.status.idle":"2024-05-27T17:05:01.561246Z","shell.execute_reply.started":"2024-05-27T17:05:01.548450Z","shell.execute_reply":"2024-05-27T17:05:01.559895Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"en_vocab , en_inv_vocab , en_seqs , en_tokenizer = tokenizer('en')\nfr_vocab , fr_inv_vocab , fr_seqs , fr_tokenizer = tokenizer('fr')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:05:01.564286Z","iopub.execute_input":"2024-05-27T17:05:01.564726Z","iopub.status.idle":"2024-05-27T17:05:01.603209Z","shell.execute_reply.started":"2024-05-27T17:05:01.564692Z","shell.execute_reply":"2024-05-27T17:05:01.601972Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/386876738.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].astype(str)\n/tmp/ipykernel_33/386876738.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: x.lower())\n/tmp/ipykernel_33/386876738.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: re.sub(\"[^A-Za-z\\s]\",\"\",x))\n/tmp/ipykernel_33/386876738.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: x.replace(\"\\s+\",\" \"))\n/tmp/ipykernel_33/386876738.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: \" \".join([word for word in x.split()]))\n/tmp/ipykernel_33/386876738.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].astype(str)\n/tmp/ipykernel_33/386876738.py:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x : x.lower())\n/tmp/ipykernel_33/386876738.py:11: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: re.sub(r'\\d','',x))\n/tmp/ipykernel_33/386876738.py:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: re.sub(r'\\s+',' ',x))\n/tmp/ipykernel_33/386876738.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,।]\", \"\", x))\n/tmp/ipykernel_33/386876738.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = data[col].apply(lambda x: x.strip())\n/tmp/ipykernel_33/386876738.py:15: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[col] = \"<sos> \" + data[col] + \" <eos>\"\n","output_type":"stream"}]},{"cell_type":"code","source":"model = tf.keras.Sequential([ tf.keras.layers.Embedding(input_dim=10000 ,output_dim=768, input_length=100)])\ndef embedder(text):\n    global model\n    cls_embedding = model(text)\n    #Positional encoding \n    seq_len,d,n=100,768,10000\n    P = np.zeros((seq_len, d))\n    for k in range(seq_len):\n        for i in np.arange(int(d/2)):\n            denominator = np.power(n, 2*i/d)\n            P[k, 2*i] = np.sin(k/denominator)\n            P[k, 2*i+1] = np.cos(k/denominator)\n    #Adding positional encoding\n    cls_embedding += P\n    return tf.expand_dims(cls_embedding, axis=0)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:05:01.604523Z","iopub.execute_input":"2024-05-27T17:05:01.604867Z","iopub.status.idle":"2024-05-27T17:05:01.630055Z","shell.execute_reply.started":"2024-05-27T17:05:01.604836Z","shell.execute_reply":"2024-05-27T17:05:01.628827Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"#encoder\nWqe=tf.random.normal(shape=(1,100, 768))\nWke=tf.random.normal(shape=(1,100, 768))\nWve=tf.random.normal(shape=(1,100, 768))\nW0e=tf.random.normal(shape=(1,100, 768))\nW1e=tf.random.normal(shape=(1,100, 768))\n#decoder\nWqd=tf.random.normal(shape=(1,100, 768))\nWkd=tf.random.normal(shape=(1,100, 768))\nWvd=tf.random.normal(shape=(1,100 ,768))\nW0d=tf.random.normal(shape=(1,100 ,768))\nW1d=tf.random.normal(shape=(1,100 ,768))\nW01d=tf.random.normal(shape=(1,100, 768))\nW11d=tf.random.normal(shape=(1,100, 768))\n#train\nW0t=tf.random.normal(shape=(1,100, 768))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:05:01.631586Z","iopub.execute_input":"2024-05-27T17:05:01.631925Z","iopub.status.idle":"2024-05-27T17:05:01.786035Z","shell.execute_reply.started":"2024-05-27T17:05:01.631895Z","shell.execute_reply":"2024-05-27T17:05:01.784776Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import math\ndef encoder(embed):\n    # weights of query ,keys and values and other weights\n    global Wqe,Wke,Wve,W0e,W1e\n    #Calculating query ,keys and values\n    Query=embed*Wqe\n    Key=embed*Wke\n    Value=embed*Wve\n    # Scaled-Dot Product Attention\n    scores = tf.matmul(Query, Key, transpose_b=True) / math.sqrt(tf.cast(768, tf.float32))\n    weights = tf.keras.activations.softmax(scores)\n    result=tf.matmul(weights, Value)\n    #Add layer\n    embed+=result\n    #normalize the embeddings\n    normalized_embeddings = tf.keras.layers.LayerNormalization()(embed)\n    #feed forward layer from scratch\n    Layer1=W0e*normalized_embeddings\n    result1=tf.nn.relu(Layer1)\n    result=W1e*normalized_embeddings\n    #Add layer\n    embed+=result\n    #normalize the embeddings\n    normalized_embeddings = tf.keras.layers.LayerNormalization()(embed)\n    Key=normalized_embeddings*Wke\n    Value=normalized_embeddings*Wve\n    return [Key,Value]","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:05:01.787729Z","iopub.execute_input":"2024-05-27T17:05:01.788121Z","iopub.status.idle":"2024-05-27T17:05:01.799046Z","shell.execute_reply.started":"2024-05-27T17:05:01.788088Z","shell.execute_reply":"2024-05-27T17:05:01.797843Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def decoder(embed, arr):\n    # weights of query ,keys and values and other weights\n    global Wqd,Wkd,Wvd,W0d,W1d,W01d,W11d\n    #Calculating query ,keys and values\n    Query=embed*Wqd\n    Key=embed*Wkd\n    Value=embed*Wvd\n    # Scaled-Dot Product Attention\n    scores = tf.matmul(Query, Key, transpose_b=True) / math.sqrt(tf.cast(768, tf.float32))\n    weights = tf.keras.activations.softmax(scores)\n    result=tf.matmul(weights, Value)\n    #Add layer\n    embed+=result\n    #normalize the embeddings\n    normalized_embeddings = tf.keras.layers.LayerNormalization()(embed)\n    #feed forward layer from scratch\n    Layer1=W0d*normalized_embeddings\n    result1=tf.nn.relu(Layer1)\n    result=W1d*normalized_embeddings\n    #Add layer\n    embed+=result\n    #normalize the embeddings\n    embed = tf.keras.layers.LayerNormalization()(embed)\n    #key ,value of encodings output\n    Key,Value=arr\n    Query=embed*Wqd\n    scores = tf.matmul(Query, Key, transpose_b=True) / math.sqrt(tf.cast(768, tf.float32))\n    weights = tf.keras.activations.softmax(scores)\n    result=tf.matmul(weights, Value)\n    #Add layer\n    embed+=result\n    #normalize the embeddings\n    normalized_embeddings = tf.keras.layers.LayerNormalization()(embed)\n    #feed forward layer from scratch\n    Layer1=W01d*normalized_embeddings\n    result1=tf.nn.relu(Layer1)\n    result=W11d*normalized_embeddings\n    #Add layer\n    embed+=result\n    return embed","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:05:01.800758Z","iopub.execute_input":"2024-05-27T17:05:01.801269Z","iopub.status.idle":"2024-05-27T17:05:01.816123Z","shell.execute_reply.started":"2024-05-27T17:05:01.801230Z","shell.execute_reply":"2024-05-27T17:05:01.814892Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def train(src , trg,opt):\n    global model,tokenizer,W0t,Wqe,Wke,Wve,W0e,W1e,Wqd,Wkd,Wvd,W0d,W1d,W01d,W11d\n    encoder_output=encoder(embedder(src))\n    output_embed=embedder(trg)\n    decoder_output=decoder(output_embed,encoder_output)\n    Layer1=W0t*decoder_output\n    result=tf.nn.softmax(Layer1, axis=-1)\n    predicted_id = tf.cast(tf.argmax(result, axis=-1), tf.int64) \n    pred_sent = ' '.join([fr_tokenizer.index_word[idx] for idx in predicted_id[0].numpy() if idx != 0 and idx != 2 and idx !=3 and idx in fr_tokenizer.index_word.keys() ])\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=output_embed, logits=result))\n    return loss.numpy()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:05:01.817611Z","iopub.execute_input":"2024-05-27T17:05:01.817954Z","iopub.status.idle":"2024-05-27T17:05:01.834758Z","shell.execute_reply.started":"2024-05-27T17:05:01.817926Z","shell.execute_reply":"2024-05-27T17:05:01.833303Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_set = tf.data.Dataset.from_tensor_slices((en_seqs , fr_seqs ))\ntrain_set = train_set.shuffle(100).batch(15 , drop_remainder = True)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:05:01.838820Z","iopub.execute_input":"2024-05-27T17:05:01.839269Z","iopub.status.idle":"2024-05-27T17:05:01.872201Z","shell.execute_reply.started":"2024-05-27T17:05:01.839224Z","shell.execute_reply":"2024-05-27T17:05:01.871070Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm \ndef trainloop(EPOCHS,optimizer):\n    global W0t,Wqe,Wke,Wve,W0e,W1e,Wqd,Wkd,Wvd,W0d,W1d,W01d,W11d\n    for epoch in tqdm(range(EPOCHS)) :\n        print(f'epoch : {epoch}')\n        lossofepoch=0\n        s=0\n        for src , trg in tqdm(train_set) : \n            for i in range(15):\n                loss=train(src[i],trg[i],optimizer)\n                #backpropagation\n                W0t+=1e-6\n                Wqe+=1e-6\n                Wke+=1e-6\n                Wve+=1e-6\n                W0e+=1e-6\n                W1e+=1e-6\n                Wqd+=1e-6\n                Wkd+=1e-6\n                Wvd+=1e-6\n                W0d+=1e-6\n                W1d+=1e-6\n                W01d+=1e-6\n                W11d+=1e-6\n                loss1=train(src[i],trg[i],optimizer)\n                gradient = (loss1-loss) / 1e-6\n                W0t-=gradient*optimizer\n                Wqe-=gradient*optimizer\n                Wke-=gradient*optimizer\n                Wve-=gradient*optimizer\n                W0e-=gradient*optimizer\n                W1e-=gradient*optimizer\n                Wqd-=gradient*optimizer\n                Wkd-=gradient*optimizer\n                Wvd-=gradient*optimizer\n                W0d-=gradient*optimizer\n                W1d-=gradient*optimizer\n                W01d-=gradient*optimizer\n                W11d-=gradient*optimizer\n                lossofepoch+=loss\n                s+=1\n            print(lossofepoch/s)\ntrainloop(2,0.0001)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:05:01.873527Z","iopub.execute_input":"2024-05-27T17:05:01.873904Z","iopub.status.idle":"2024-05-27T17:09:33.114140Z","shell.execute_reply.started":"2024-05-27T17:05:01.873873Z","shell.execute_reply":"2024-05-27T17:09:33.112951Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d8568686d034ac6bc6d4417d03c9a74"}},"metadata":{}},{"name":"stdout","text":"epoch : 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d009e0ff7cd94af9853c10d904b0043c"}},"metadata":{}},{"name":"stdout","text":"1822.2404052734375\n1822.1409342447917\n1822.1191026475694\n1822.1157653808593\n1822.0970068359375\n1822.0861436631944\nepoch : 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32d9cb3dcf78499a9e41b3bf1e90ff83"}},"metadata":{}},{"name":"stdout","text":"1822.116560872396\n1822.052400716146\n1822.072998046875\n1822.0412963867188\n1822.0086100260417\n1821.9932427300348\n","output_type":"stream"}]},{"cell_type":"code","source":"def test(src):\n    decoder_input = fr_tokenizer.texts_to_sequences(['sos'])\n    for i in range(1):\n        decoder_input = tf.convert_to_tensor(np.array(decoder_input) , dtype = tf.int64)\n        print(decoder_input)\n        encoder_output=encoder(embedder(src))\n        output_embed=embedder(decoder_input)\n        decoder_output=decoder(output_embed,encoder_output)\n        Layer1=W0t*decoder_output\n        result=tf.nn.softmax(Layer1, axis=-1)\n        predicted_id = max(tf.cast(tf.argmax(result, axis=-1), tf.int64)[0])\n        decoder_input = tf.stack([decoder_input, [[predicted_id]]], axis=0)\n    return decoder_input\ntest(en_seqs[50])","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:25:09.695340Z","iopub.execute_input":"2024-05-27T17:25:09.695775Z","iopub.status.idle":"2024-05-27T17:25:10.522291Z","shell.execute_reply.started":"2024-05-27T17:25:09.695741Z","shell.execute_reply":"2024-05-27T17:25:10.521092Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"tf.Tensor([[2]], shape=(1, 1), dtype=int64)\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(2, 1, 1), dtype=int64, numpy=\narray([[[  2]],\n\n       [[761]]])>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}